# Github Blog
- 공부한 내용을 정리하여 포스팅하는 personal archive로 사용하고 있습니다.
- 혹시 잘못된 내용이나, 문의가 있으시면 블로그에 나와있는 주소로 연락주세요!

<table>
  <tr>
      <th colspan="4">Paper</th>
  </tr>
  <tr>
    <th>Num</th>
    <th>Title</th>
    <th>Review</th> 
    <th>Paper</th>
  </tr>

  <tr>
    <td>1</td>
    <td>resNet[1] Deep Residual Learning for Image Recognition(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/resnet/paperreview/2018/02/10/resNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1512.03385">paper</a></td>
  </tr>

  <tr>
    <td>2</td>
    <td>resNet[2] Identity Mappings in Deep Residual Networks(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/resnet/paperreview/2018/02/11/resNet2.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1603.05027">paper</a></td>
  </tr>

  <tr>
    <td>3</td>
    <td>resNet[3] Residual Networks Behave Like Ensembles of Relatively Shallow Networks(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/resnet/paperreview/2018/02/11/resNet3.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1605.06431">paper</a></td>
  </tr>

  <tr>
    <td>4</td>
    <td>VDCNN[1] Very Deep Convolutional Networks for Text Classification(2016) </td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/nlp/paperreview/2018/02/17/VDCNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1606.01781">paper</a></td>
  </tr>

  <tr>
    <td>5</td>
    <td>CoVe[1] Learned in Translation: Contextualized Word Vectors(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/nlp/paperreview/2018/02/17/CoVe1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1708.001075">paper</a></td>
  </tr>

  <tr>
    <td>6</td>
    <td>wordCNN[1] Convolutional Neural Networks for Sentence Classification(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/nlp/paperreview/2018/02/19/wordCNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1408.5882">paper</a></td>
  </tr>

  <tr>
    <td>7</td>
    <td>wordCNN[2] Sensitivity Analysis of CNN sentence classification(2015) - Review(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/nlp/paperreview/2018/02/19/wordCNN2.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1510.03820">paper</a></td>
  </tr>

  <tr>
    <td>8</td>
    <td>charCNN[1] Character level Convolutional Networks for Text Classification(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/nlp/paperreview/2018/02/20/charCNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1509.01626">paper</a></td>
  </tr>

  <tr>
    <td>9</td>
    <td>LSTM[1] Long Short Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/nlp/paperreview/2018/02/21/LSTM1.html">review</a></td>
    <td><a href="http://www.isca-speech.org/archive/archive_papers/interspeech_2014/i14_0338.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>10</td>
    <td>BLSTM[1] Bi-directional LSTM Recurrent Neural Network for Chinese Word Segmentation(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/nlp/paperreview/2018/02/21/BLSTM1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1602.04874">paper</a></td>
  </tr>

  <tr>
    <td>11</td>
    <td>DBLSTM[1] Hybrid Speech Recognition With Deep Bidirectional LSTM(2013)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/nlp/paperreview/2018/02/21/DBLSTM1.html">review</a></td>
    <td><a href="https://www.cs.toronto.edu/~graves/asru_2013.pdf">paper</a></td>
  </tr>

  <tr>
    <td>12</td>
    <td>Attention[1] Neural Machine Translation by Jointly Learning to Align and Translate(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/attention/nlp/paperreview/2018/02/23/attention1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1409.0473">paper</a></td>
  </tr>

  <tr>
    <td>13</td>
    <td>Attention[2] Effective Approaches to Attention based Neural Machine Translation(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/attention/nlp/paperreview/2018/02/23/attention2.html">review</a></td>
    <td><a href="http://aclweb.org/anthology/D15-1166">paper</a></td>
  </tr>

  <tr>
    <td>14</td>
    <td>BiDAF[1] Editing Bidirectional Attention Flow for Machine Comprehension(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/attention/nlp/paperreview/2018/02/23/BiDAF1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1611.01603">paper</a></td>
  </tr>
  
  <tr>
    <td>15</td>
    <td>Seq2Seq[1] Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/seq2seq/nlp/paperreview/2018/02/24/seq2seq1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1406.1078">paper</a></td>
  </tr>

  <tr>
    <td>16</td>
    <td>Seq2Seq[2] Sequence to Sequence Learning with Neural Networks(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/seq2seq/nlp/paperreview/2018/02/25/seq2seq2.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1409.3215">paper</a></td>
  </tr>
  
  <tr>
    <td>17</td>
    <td>GRU[1] Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/gru/paperreview/2018/02/27/GRU1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1412.3555">paper</a></td>
  </tr>
  
  <tr>
    <td>18</td>
    <td>charCNN[2] Character Aware Neural Language Model(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/charcnn/nlp/paperreview/2018/02/27/charCNN2.html">review</a></td>
    <td><a href=https://arxiv.org/abs/1508.06615">paper</a></td>
  </tr>
  
  <tr>
    <td>19</td>
    <td>char-word LSTM[1] Character Word LSTM Language Models(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/nlp/paperreview/2018/02/28/char-word-LSTM1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1704.02813">paper</a></td>
  </tr>
  
  <tr>
    <td>20</td>
    <td>BLSTM-CNN-CRF[1] Character Word LSTM Language Models(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/cnn/lstm/charcnn/nlp/paperreview/2018/03/01/BLSTM-CNN-CRF1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1603.01354">paper</a></td>
  </tr>
      
  <tr>
    <td>21</td>
    <td>Seq2Seq[3] A Persona Based Neural Conversation Model(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/lstm/seq2seq/nlp/paperreview/2018/03/01/seq2seq3.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1603.06155">paper</a></td>
  </tr>
  
  <tr>
    <td>22</td>
    <td>QRNN[1] Quasi Recurrent Neural Networks(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/qrnn/paperreview/2018/03/02/QRNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1611.01576">paper</a></td>
  </tr>
  
  <tr>
    <td>23</td>
    <td>SRU[1] Training RNNs as Fast as CNNs(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/rnn/sru/paperreview/2018/03/03/SRU1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1709.02755">paper</a></td>
  </tr>
  
  <tr>
    <td>24</td>
    <td>ByteNet[1] Neural Machine Translation in Linear Time(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/bytenet/paperreview/2018/03/05/byteNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1610.10099">paper</a></td>
  </tr>
  
  <tr>
    <td>25</td>
    <td>Inception[1] Going Deeper with Convolutions(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/inception/paperreview/2018/03/12/Inception1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1409.4842">paper</a></td>
  </tr>
  
  <tr>
    <td>26</td>
    <td>Inception[2] Rethinking the Inception Architecture for Computer Vision(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/inception/paperreview/2018/03/13/Inception2.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1512.00567">paper</a></td>
  </tr>
      
  <tr>
    <td>27</td>
    <td>Inception[3] Inception v4, Inception ResNet and the Impact of Residual Connections on Learning(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/inception/paperreview/2018/03/17/Inception3.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1602.07261">paper</a></td>
  </tr>
  
  <tr>
    <td>28</td>
    <td>Xception[1] Xception: Deep Learning with Depthwise Separable Convolutions(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/inception/xception/paperreview/2018/03/25/Xception1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1610.02357">paper</a></td>
  </tr>
  
  <tr>
    <td>29</td>
    <td>sliceNet[1] Depthwise Separable Convolutions for Neural Machine Translation(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/slicenet/paperreview/2018/04/03/sliceNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1706.03059">paper</a></td>
  </tr>
  
  <tr>
    <td>30</td>
    <td>denseNet[1] Densely Connected Convolutional Networks(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/resnet/densenet/paperreview/2018/04/08/denseNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1608.06993">paper</a></td>
  </tr>
  
  <tr>
    <td>31</td>
    <td>Spark[1] Spark: Cluster Computing with Working Sets(2010)</td>
    <td><a href="https://hwkim94.github.io/distributed-computing/spark/rdd/paperreview/2018/05/15/Spark1.html">review</a></td>
    <td><a href="http://static.usenix.org/legacy/events/hotcloud10/tech/full_papers/Zaharia.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>32</td>
    <td>Spark[2] Resilient Distributed Datasets: A Fault Tolerant Abstraction for In Memory Cluster Computing(2012)</td>
    <td><a href="https://hwkim94.github.io/distributed-computing/spark/rdd/paperreview/2018/05/15/Spark2.html">review</a></td>
    <td><a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>33</td>
    <td>Distributed DL[1] Parallel and Distributed Deep Learning(2016)</td>
    <td><a href="https://hwkim94.github.io/distributed-computing/deeplearning/paperreview/2018/05/15/Distributed-DL1.html">review</a></td>
    <td><a href="https://web.stanford.edu/~rezab/classes/cme323/S16/projects_reports/hedge_usmani.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>34</td>
    <td>Distributed DL[2] Large Scale Distributed Deep Networks(2012)</td>
    <td><a href="https://hwkim94.github.io/distributed-computing/deeplearning/paperreview/2018/05/16/Distributed-DL2.html">review</a></td>
    <td><a href="http://www.cs.toronto.edu/~ranzato/publications/DistBeliefNIPS2012_withAppendix.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>35</td>
    <td>AlexNet[1] ImageNet Classification with Deep Convolutional Neural Networks(2012)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/alexnet/paperreview/2018/05/20/AlexNet1.html">review</a></td>
    <td><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>36</td>
    <td>Audio Style Transfer[1] Neural Style Transfer for Audio Spectrograms(2018)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/audio/style-transfer/paperreview/alexnet/2018/05/21/Audio-Style-Transfer1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1801.01589">paper</a></td>
  </tr>
  
  <tr>
    <td>37</td>
    <td>Audio Style Transfer[2] Style Transfer for Prosodic Speech(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/audio/style-transfer/paperreview/2018/05/21/Audio-Style-Transfer2.html">review</a></td>
    <td><a href="http://web.stanford.edu/class/cs224s/reports/Anthony_Perez.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>38</td>
    <td>Audio Style Transfer[3] Music Style Transfer: A Position Paper(2018)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/audio/style-transfer/paperreview/2018/05/22/Audio-Style-Transfer3.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1803.06841">paper</a></td>
  </tr>
  
  <tr>
    <td>39</td>
    <td>Audio Style Transfer[4] AUDIO STYLE TRANSFER(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/audio/style-transfer/paperreview/2018/05/22/Audio-Style-Transfer4.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1710.11385">paper</a></td>
  </tr>
  
  <tr>
    <td>40</td>
    <td>WaveNet[1] WaveNet: A Generative Model for Raw Audio(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/wavenet/paperreview/2018/05/23/WaveNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1609.03499">paper</a></td>
  </tr>
  
  <tr>
    <td>41</td>
    <td>Audio Style Transfer[5] A Universal Music Translation Network(2018)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/audio/style-transfer/wavenet/autoencoder/paperreview/2018/05/25/Audio-Style-Transfer5.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1805.07848">paper</a></td>
  </tr>
  
  <tr>
    <td>42</td>
    <td>Transformer[1] Attention Is All You Need(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/attention/nlp/transformer/paperreview/2018/08/12/Transformer1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1706.03762">paper</a></td>
  </tr>
  
  <tr>
    <td>43</td>
    <td>R-CNN[1] Rich feature hierarchies for accurate object detection and semantic segmentation(2014)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-cnn/paperreview/2018/09/21/R-CNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1311.2524">paper</a></td>
  </tr>
  
  <tr>
    <td>44</td>
    <td>Fast R-CNN[1] Fast R CNN(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-cnn/paperreview/2018/09/22/Fast-R-CNN1.html">review</a></td>
    <td><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>45</td>
    <td>Faster R-CNN[1] Faster R CNN: Towards Real Time Object Detection with Region Proposal Networks(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-cnn/paperreview/2018/09/22/Fater-R-CNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1506.01497">paper</a></td>
  </tr>
  
  <tr>
    <td>46</td>
    <td>YOLO[1] You Only Look Once: Unified, Real Time Object Detection(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/yolo/paperreview/2018/09/22/YOLO1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1506.02640">paper</a></td>
  </tr>
  
  <tr>
    <td>47</td>
    <td>YOLO[2] YOLO9000: Better, Faster, Stronger(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/yolo/paperreview/2018/09/23/YOLO2.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1612.08242">paper</a></td>
  </tr>
  
  <tr>
    <td>48</td>
    <td>YOLO[3] YOLOv3: An Incremental Improvement(2018)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/yolo/paperreview/2018/09/23/YOLO3.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1804.02767">paper</a></td>
  </tr>
  
  <tr>
    <td>49</td>
    <td>RetinaNet[1] Focal Loss for Dense Object Detection(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/retinanet/focal-loss/paperreview/2018/09/24/retinaNet1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1708.02002">paper</a></td>
  </tr>
  
  <tr>
    <td>50</td>
    <td>SSD[1] SSD: Single Shot MultiBox Detector(2015)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/ssd/paperreview/2018/09/27/SSD1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1512.02325">paper</a></td>
  </tr>
  
  <tr>
    <td>51</td>
    <td>DSSD[1] DSSD: Deconvolutional Single Shot Detector(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/dssd/paperreview/2018/09/28/DSSD1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1701.06659">paper</a></td>
  </tr>
  
  <tr>
    <td>52</td>
    <td>Light-Head R-CNN[1] Light-Head R-CNN: In Defense of Two Stage Object Detector(2017)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-cnn/paperreview/2018/09/29/Light-Head-R-CNN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1711.07264">paper</a></td>
  </tr>
  
  <tr>
    <td>53</td>
    <td>R-FCN[1] R-FCN: Object Detection via Region based Fully Convolutional Networks(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-fcn/paperreview/2018/09/30/R-FCN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1605.06409">paper</a></td>
  </tr>
  
  <tr>
    <td>54</td>
    <td>R-FCN[2] R-FCN++: Towards Accurate Region Based Fully Convolutional Networks for Object Detection(2018)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/r-fcn/paperreview/2018/09/30/R-FCN2.html">review</a></td>
    <td><a href="http://www.skicyyu.org/Paper/RFCN_plus_plus.pdf">paper</a></td>
  </tr>
  
  <tr>
    <td>55</td>
    <td>FPN[1] Feature Pyramid Networks for Object Detection(2016)</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/image-detection/fpn/paperreview/2018/10/01/FPN1.html">review</a></td>
    <td><a href="https://arxiv.org/abs/1612.03144">paper</a></td>
  </tr>
  
</table>


<table>
  <tr>
      <th colspan="4">Implementation</th>
  </tr>
  <tr>
    <th>Num</th>
    <th>Title</th>
    <th>Review</th> 
    <th>Code</th>
  </tr>

  <tr>
    <td>1</td>
    <td>resNet[4]</td>
    <td><a href="https://hwkim94.github.io/deeplearning/cnn/resnet/implementation/tensorflow/2018/02/21/resNet4.html">review</a></td>
    <td><a href="https://github.com/hwkim94/hwkim94.github.io/tree/master/Implementation/resNet">code</a></td>
  </tr>
</table>

### Support:

If you want the good work to continue please support us on

* [PAYPAL](https://www.paypal.me/ishandutta2007)
* [BITCOIN ADDRESS: 3LZazKXG18Hxa3LLNAeKYZNtLzCxpv1LyD](https://www.coinbase.com/join/5a8e4a045b02c403bc3a9c0c)
